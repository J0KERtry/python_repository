{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8orT99g98s90qvnIUyW55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J0KERtry/python_repository/blob/main/%E5%AE%9F%E5%8A%9B%E3%83%86%E3%82%B9%E3%83%88_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 必要なものを準備"
      ],
      "metadata": {
        "id": "72lcndUkbY5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch_lightning==1.8.3\n",
        "!pip install -q torchmetrics==0.10.3"
      ],
      "metadata": {
        "id": "2SR2WrBuPgdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a1c9b5-3f77-4c60-91e8-2715d70cdb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O-A0L4R-Rir"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "import torchmetrics\n",
        "from torchmetrics.functional import accuracy\n",
        "%matplotlib inline\n",
        "plt.style.use('bmh')\n",
        "plt.rcParams['figure.figsize'] = 8, 6\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "oe = OrdinalEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, testデータの取得\n",
        "path = '/content/bank_train.csv'\n",
        "path_t = '/content/bank_test02.csv'\n",
        "train = pd.read_csv(path)\n",
        "test = pd.read_csv(path_t)\n",
        "train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "420fdoMqPMWc",
        "outputId": "2cc43e26-2a01-465d-e18c-54b5ee5c4f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-67e95606051b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/bank_train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/bank_test02.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/bank_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **データの前処理**\n",
        "\n",
        "前処理の流れ\n",
        "1.   重複行の削除\n",
        "\n",
        "2.   欠損値の処理\n",
        " - age　<-　平均値で補完\n",
        " - default　<-　最頻値で補完\n",
        " - pdays　<-　最頻値で補完\n",
        "\n",
        "\n",
        "3.   特徴量エンジニアリング\n",
        " 1. job の 欠損値を unknown と変換\n",
        " 2. job を職種別に分類\n",
        "\n",
        "4.   外れ値除去\n",
        " - default の外れ値を除去　(3σ法)\n",
        "\n",
        "5. カテゴリカル変数の処理\n",
        " - One-Hot-Encoding ( job, education以外 )\n",
        " - Label-Encoding ( job, education )\n",
        "\n"
      ],
      "metadata": {
        "id": "0nHf-jGRUF1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.　重複行の削除**"
      ],
      "metadata": {
        "id": "8MrkpTEWSr9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train の重複行を確認\n",
        "print(train.duplicated(keep=False).value_counts())"
      ],
      "metadata": {
        "id": "Qc-pIwJmSeyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train の重複行を削除\n",
        "train = train.drop_duplicates()\n",
        "train.shape"
      ],
      "metadata": {
        "id": "GeW5gKxBS-hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.　欠損値の処理**"
      ],
      "metadata": {
        "id": "7XOcnj65RTim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test の欠損値を確認\n",
        "print('train の欠損値')\n",
        "print(train.isnull().sum()) \n",
        "print('-------------------------')\n",
        "print('test の欠損値')\n",
        "print(test.isnull().sum())"
      ],
      "metadata": {
        "id": "FMtKdQzFOfP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### age"
      ],
      "metadata": {
        "id": "rSUtlKsxmlPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# age の分布を可視化\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(train['age'])\n",
        "plt.title('train')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(test['age'])\n",
        "plt.title('test')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NKKsZPuVSDBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'age' の代表値を確認\n",
        "print('train[age] の平均値, 中央値:',' ', train['age'].mean(), ' ', train['age'].median())\n",
        "print('test[age] の平均値, 中央値:','  ', test['age'].mean(),' ', test['age'].median())"
      ],
      "metadata": {
        "id": "OBRItxYMSDMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# age の欠損値を平均値で補完\n",
        "train = train.fillna({'age': int(train['age'].mean())})\n",
        "test = test.fillna({'age': int(test['age'].mean())})"
      ],
      "metadata": {
        "id": "QfN9kG3oVgOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### default"
      ],
      "metadata": {
        "id": "9-7PJrtXs5E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default の分布を可視化\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "train['default'].hist();\n",
        "plt.title('train')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "test['default'].hist();\n",
        "plt.title('test')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZbC5hMR2ksk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default の欠損値を no で補完\n",
        "train = train.fillna({'default': 'no'})\n",
        "test = test.fillna({'default': 'no'})"
      ],
      "metadata": {
        "id": "s1kDVvuytQrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pdays"
      ],
      "metadata": {
        "id": "IGBy1duImfl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pdays の分布を可視化\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(train['pdays'])\n",
        "plt.title('train')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(test['pdays'])\n",
        "plt.title('test')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RrifiLyG59jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pdays の欠損値を最頻値で補完\n",
        "train = train.fillna({'pdays': train['pdays'].mode()[0]})\n",
        "test = test.fillna({'pdays': test['pdays'].mode()[0]})"
      ],
      "metadata": {
        "id": "t6H6Q56KSCkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.　特徴量エンジニアリング**\n",
        "以下の職業でクラス分け\n",
        "0. blue-collar　＜ 現場作業 ＞\n",
        "1. services   　　＜ サービス業 ＞\n",
        "2. technician 　＜ 技術者 ＞\n",
        "3. management, admin　　＜ 管理者 ＞\n",
        "4. entrepreneur, self-employed   　＜ 自営業 ＞\n",
        "5. housemaid　＜ 家政婦 ＞\n",
        "6. retired, unemployed, student    　＜収入源無し＞\n",
        "7. unknown, NaN　＜情報なし＞"
      ],
      "metadata": {
        "id": "kipkXd0UVgLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'job' の欠損値を 'unknown' と分類\n",
        "train.loc[train['job'].isna(), 'job'] = 'unknown'\n",
        "test.loc[test['job'].isna(), 'job'] = 'unknown'"
      ],
      "metadata": {
        "id": "TGxNKoUM6iwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# クラス分けの定義\n",
        "class_0 = ['blue-collar']\n",
        "class_1 = ['services']\n",
        "class_2 = ['technician']\n",
        "class_3 = ['management', 'admin.']\n",
        "class_4 = ['entrepreneur', 'self-employed']\n",
        "class_5 = ['housemaid']\n",
        "class_6 = ['retired', 'unemployed', 'student']\n",
        "class_7 = ['unknown']"
      ],
      "metadata": {
        "id": "cIx59LB7R3me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train の特徴量エンジニアリング\n",
        "job = []\n",
        "for i in train['job']:\n",
        "    if i in class_0:\n",
        "        job.append('class0')\n",
        "    elif i in class_1:\n",
        "        job.append('class1')\n",
        "    elif i in class_2:\n",
        "        job.append('class2')\n",
        "    elif i in class_3:\n",
        "        job.append('class3')\n",
        "    elif i in class_4:\n",
        "        job.append('class4')\n",
        "    elif i in class_5:\n",
        "        job.append('class5')\n",
        "    elif i in class_6:\n",
        "        job.append('class6')\n",
        "    elif i in class_7:\n",
        "        job.append('class7')\n",
        "\n",
        "# 置換\n",
        "train['job'] = job"
      ],
      "metadata": {
        "id": "4yF3BKei73xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test の特徴量エンジニアリング\n",
        "job = []\n",
        "for i in test['job']:\n",
        "    if i in class_0:\n",
        "        job.append('class0')\n",
        "    elif i in class_1:\n",
        "        job.append('class1')\n",
        "    elif i in class_2:\n",
        "        job.append('class2')\n",
        "    elif i in class_3:\n",
        "        job.append('class3')\n",
        "    elif i in class_4:\n",
        "        job.append('class4')\n",
        "    elif i in class_5:\n",
        "        job.append('class5')\n",
        "    elif i in class_6:\n",
        "        job.append('class6')\n",
        "    elif i in class_7:\n",
        "        job.append('class7')\n",
        "\n",
        "# 置換\n",
        "test['job'] = job"
      ],
      "metadata": {
        "id": "4bNiyKiI74Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "id": "XLsEuO_gZG3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(3)"
      ],
      "metadata": {
        "id": "9nlcEVXn8FEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.　外れ値除去**\n"
      ],
      "metadata": {
        "id": "je-A4IyWfXSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train['balance'] の分布を可視化\n",
        "sns.distplot(train['balance']);"
      ],
      "metadata": {
        "id": "Rs01TuEPaQJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu = train['balance'].mean()   # train['balance'] の平均値\n",
        "sigma = train['balance'].std()   # train['balance'] の標準偏差\n",
        "\n",
        "# 3σ法で train データを取得\n",
        "_train = train[(mu - 3 * sigma <= train['balance']) & (train['balance'] <= mu + 3 * sigma)]"
      ],
      "metadata": {
        "id": "pWGU93WYfliX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 外れ値除去後の分布\n",
        "sns.distplot(_train['balance']);"
      ],
      "metadata": {
        "id": "xvKlpBd5gKbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 元のデータ数と比較\n",
        "len(train), len(_train)"
      ],
      "metadata": {
        "id": "j8XTJDEmWNEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.　カテゴリカル変数の変換**\n",
        "### 　One-hot-encording"
      ],
      "metadata": {
        "id": "FSj6chxsU8c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリカル変数のカラム取得\n",
        "train_obj = _train.select_dtypes(include='object')\n",
        "test_obj = test.select_dtypes(include='object')\n",
        "\n",
        "# カテゴリカル変数の数を確認\n",
        "print('train のカテゴリカル変数')\n",
        "print(train_obj.nunique())\n",
        "print('-------------------------')\n",
        "print('test のカテゴリカル変数')\n",
        "print(test_obj.nunique())"
      ],
      "metadata": {
        "id": "IkRrz2l_T9QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリカル変数を One-hotエンコーディング\n",
        "train_en = pd.get_dummies(_train, columns=['marital', 'default', 'housing', 'loan', 'poutcome', 'result'], drop_first=True)\n",
        "test_en = pd.get_dummies(test, columns=['marital', 'default', 'housing', 'loan', 'poutcome', 'result'], drop_first=True)"
      ],
      "metadata": {
        "id": "o95y6K4rXkEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Label Encoding"
      ],
      "metadata": {
        "id": "NeCYc5xAXUpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# job, education をLabelエンコーディング\n",
        "\n",
        "# train_en に対してエンコーディング\n",
        "encoded = oe.fit_transform(train_en[['job', 'education']].values)\n",
        "train_en[['job', 'education']] = encoded\n",
        "\n",
        "# test_en に対してエンコーディング\n",
        "encoded = oe.fit_transform(test_en[['job', 'education']].values)\n",
        "test_en[['job', 'education']] = encoded"
      ],
      "metadata": {
        "id": "HCbiqPLJKAnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# すべてのカラムが数値に変換されているか確認 (train)\n",
        "train_en.head(3)"
      ],
      "metadata": {
        "id": "X2Z-oLxxFQ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# すべてのカラムが数値に変換されているか確認 (test)\n",
        "test_en.head(3)"
      ],
      "metadata": {
        "id": "EsffLiobegP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 前処理終了後のデータ\n",
        "train_en.shape, test_en.shape"
      ],
      "metadata": {
        "id": "4FoASJ-RU1Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ニューラルネットワーク**"
      ],
      "metadata": {
        "id": "9MvfKmWKsrne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **データの準備**\n",
        " - 入力値　result_success 以外\n",
        " - 目標値　result_success\n",
        " - train：val ＝ 8：2\n",
        " - バッチサイズ　200"
      ],
      "metadata": {
        "id": "ZqGslN__XQQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(0)\n",
        "\n",
        "# 入力値と目標値に分割\n",
        "x_train = train_en.drop('result_success', axis=1).values\n",
        "t_train = train_en['result_success'].values\n",
        "x_test = test_en.drop('result_success', axis=1).values\n",
        "t_test = test_en['result_success'].values\n",
        "\n",
        "# PyTorch の Tensor 型へ変換\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "t_train = torch.tensor(t_train, dtype=torch.int64)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "t_test = torch.tensor(t_test, dtype=torch.int64)\n",
        "\n",
        "# 入力値と目標値をまとめる\n",
        "dataset = torch.utils.data.TensorDataset(x_train, t_train)\n",
        "_dataset = torch.utils.data.TensorDataset(x_test, t_test)\n",
        "\n",
        "# 各データセットのサンプル数を決定\n",
        "n_train = int(len(dataset) * 0.9)\n",
        "n_val = int(len(dataset) - n_train)\n",
        "\n",
        "# データセットの分割\n",
        "train, val = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
        "\n",
        "# バッチサイズの定義\n",
        "batch_size = 200\n",
        "\n",
        "# DataLoader に変換\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(_dataset, batch_size)"
      ],
      "metadata": {
        "id": "0Kwkfa5WFQoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ニューラルネットワークの概要**\n",
        "\n",
        "\n",
        "ニューラルネットワークの構造\n",
        " - 3層構造 \n",
        "  - 入力層　14ノード\n",
        "  - 中間層1　1000ノード\n",
        "  - 中間層2　100ノード\n",
        "  - 出力層　1ノード\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "活性化関数\n",
        " - sigmoid \n",
        "  - 一般的に2値分類で利用される\n",
        "\n",
        "損失関数\n",
        " - binary_cross_entropy_with_logits\n",
        "  - 2値分類で利用される binary_cross_entropy よりも安定\n",
        "\n",
        "最適化関数\n",
        " - RAdam (学習率　0.0005）\n",
        "  - 収束性、安定性が高い\n"
      ],
      "metadata": {
        "id": "opgKLo1WRFnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        n1 = 14\n",
        "        n2 = 1000\n",
        "        n3 = 100\n",
        "        self.bn1 = nn.BatchNorm1d(n1)\n",
        "        self.bn2 = nn.BatchNorm1d(n2)\n",
        "        self.fc1 = nn.Linear(n1, n2)\n",
        "        self.fc2 = nn.Linear(n2, n3)\n",
        "        self.fc3 = nn.Linear(n3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.bn1(x)\n",
        "        h = F.sigmoid(self.fc1(h))\n",
        "        h = self.bn2(h)\n",
        "        h = F.sigmoid(self.fc2(h))\n",
        "        h = self.fc3(h)\n",
        "        return h\n",
        "\n",
        "    # trainデータに対する処理\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y, t.unsqueeze(-1).float())\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_acc', accuracy(F.sigmoid(y), t), on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    # valデータに対する処理\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y, t.unsqueeze(-1).float())\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.log('val_acc', accuracy(F.sigmoid(y), t), on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    # testデータに対する処理\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y, t.unsqueeze(-1).float())\n",
        "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.log('test_acc', accuracy(F.sigmoid(y), t), on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    # 最適化\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.RAdam(self.parameters(), lr=0.0005)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "fAGrkOXbNEHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(0)\n",
        "\n",
        "# インスタンス化\n",
        "net = Net()\n",
        "\n",
        "# 学習の実行\n",
        "logger = CSVLogger(save_dir='logs', name='my_exp')\n",
        "trainer = pl.Trainer(max_epochs=18, deterministic=True, logger=logger)\n",
        "trainer.fit(net, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "UBNIBdJ6fjFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習ログの取得\n",
        "log = pd.read_csv('logs/my_exp/version_2/metrics.csv')\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "# loss の推移\n",
        "plt.subplot(1,2,1)\n",
        "log[['train_loss_epoch', 'epoch']].dropna(how='any', axis=0).reset_index()['train_loss_epoch'].plot();\n",
        "log[['val_loss', 'epoch']].dropna(how='any', axis=0).reset_index()['val_loss'].plot();\n",
        "plt.title('loss')\n",
        "plt.legend()\n",
        "\n",
        "# accuracy の推移\n",
        "plt.subplot(1,2,2)\n",
        "log[['train_acc_epoch', 'epoch']].dropna(how='any', axis=0).reset_index()['train_acc_epoch'].plot();\n",
        "log[['val_acc', 'epoch']].dropna(how='any', axis=0).reset_index()['val_acc'].plot();\n",
        "plt.title('accuracy')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "YdQn5mzAhQ95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **テスト用データの検証結果**"
      ],
      "metadata": {
        "id": "5Af-FOqHs98B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testデータで検証\n",
        "trainer.test(test_dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "7GQ7PkXcvURX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **accuracy　 89.227 %**\n",
        "## **loss　0.32639**"
      ],
      "metadata": {
        "id": "yNf7l7vsAGcG"
      }
    }
  ]
}